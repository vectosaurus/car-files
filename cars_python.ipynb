{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cars\" data-toc-modified-id=\"Cars-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cars</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Read-the-data\" data-toc-modified-id=\"Read-the-data-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Read the data</a></span></li><li><span><a href=\"#Balance-the-data\" data-toc-modified-id=\"Balance-the-data-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Balance the data</a></span></li><li><span><a href=\"#Split-the-data\" data-toc-modified-id=\"Split-the-data-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Split the data</a></span></li><li><span><a href=\"#Using-Imbalanced-Data\" data-toc-modified-id=\"Using-Imbalanced-Data-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Using Imbalanced Data</a></span></li></ul></li><li><span><a href=\"#Model-Building\" data-toc-modified-id=\"Model-Building-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Model Building</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Decision-Tress\" data-toc-modified-id=\"Decision-Tress-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Decision Tress</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Multi-Layer-Perceptron\" data-toc-modified-id=\"Multi-Layer-Perceptron-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Multi Layer Perceptron</a></span></li></ul></li><li><span><a href=\"#Accuracy-Metrics\" data-toc-modified-id=\"Accuracy-Metrics-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Accuracy Metrics</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Results</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_balancing = False\n",
    "test_train_split = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.arff.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable has an uneven distribution with some classes occurring far more number of times than the others. The improve model performance we need to balance the data before. We will use `SMOTE` in this particular case. Other methods to oversample data are `ADASYN`. We will use the `imbalanced-learn` package for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data_balancing:\n",
    "    covariates = df.columns[0:df.shape[1]-1]\n",
    "    df_covar_dumm = pd.get_dummies(df.loc[:, covariates])\n",
    "    label = df.columns.tolist()[-1]\n",
    "    smote = SMOTE(ratio='auto', random_state=42, k=None, k_neighbors=5, m=None,\n",
    "                  m_neighbors=10, out_step=0.5, kind='regular', svm_estimator=None, n_jobs=1)\n",
    "    data_resampled, label_resampled = smote.fit_sample(\n",
    "        df_covar_dumm, df.loc[:, label])\n",
    "    balancd_data = pd.DataFrame(data_resampled)\n",
    "    balancd_data.loc[:, balancd_data.shape[1]] = label_resampled\n",
    "    balancd_data.columns = df_covar_dumm.columns.tolist()+[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_train_split:\n",
    "    df_train = balancd_data.sample(axis=0, frac=0.7, random_state=42, weights=None)\n",
    "    ind_test = list(set(balancd_data.index.tolist()).difference(\n",
    "        set(df_train.index.values)))\n",
    "    df_test = balancd_data.iloc[ind_test, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not data_balancing:\n",
    "    covariates = df.columns[0:df.shape[1]-1]\n",
    "    df_covar_dumm = pd.get_dummies(df.loc[:, covariates])\n",
    "    label = df.columns.tolist()[-1]\n",
    "    df_covar_dumm.loc[:, label] = df.loc[:,label]\n",
    "    balancd_data = df_covar_dumm\n",
    "\n",
    "if not test_train_split:\n",
    "    df_train = balancd_data\n",
    "    df_test = balancd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build four models - Logistic Regression, Decision Trees, Random Forest, Multi Layer Perceptron. For each of these models, we will calculate the level wise classification metrics - accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from io import StringIO\n",
    "\n",
    "X_train = df_train.iloc[:, 0:21]\n",
    "y_train = df_train.iloc[:, 21]\n",
    "X_test = df_test.iloc[:, 0:21]\n",
    "y_test = df_test.iloc[:, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_logreg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "                                  random_state=42, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "_ = model_logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                                  max_features=None, random_state=42, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
    "\n",
    "_ = model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100, criterion='entropy', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                                  max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=42, verbose=0, warm_start=False, class_weight=None)\n",
    "\n",
    "_ = model_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate='adaptive', learning_rate_init=0.003, power_t=0.5, max_iter=200,\n",
    "                          shuffle=True, random_state=42, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "_ = model_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_logreg = model_logreg.predict(X_test)\n",
    "predictions_dt = model_dt.predict(X_test)\n",
    "predictions_rf = model_rf.predict(X_test)\n",
    "predictions_mlp = model_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score\n",
    "\n",
    "def class_wise_accuracy(y_true,y_pred,average=None,labels=None):\n",
    "    levels = list(set(y_true).intersection(set(y_pred)))\n",
    "    levels.sort()\n",
    "    accuracy_by_class = []\n",
    "    for each_level in levels:\n",
    "        relevant_cases = [each_true_label == each_level for each_true_label in y_true]\n",
    "        lvl_y_true = [y_true[i] for i,relevant_case in enumerate(relevant_cases) if relevant_case]\n",
    "        lvl_y_pred = [y_pred[i] for i,relevant_case in enumerate(relevant_cases) if relevant_case]\n",
    "        accuracy_by_class.append(accuracy_score(lvl_y_true, lvl_y_pred))\n",
    "    return [x for _,x in sorted(zip(labels,accuracy_by_class))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# order of reporting\n",
    "label_order = ['acc', 'vgood', 'good', 'unacc']\n",
    "label_order.sort()\n",
    "\n",
    "# variable naming\n",
    "models = [\"logreg\",\"dt\",\"rf\",\"mlp\"]\n",
    "metrics = [\"precision\",\"recall\",\"accuracy\"]\n",
    "\n",
    "# calculate metrics\n",
    "metric_methods = [precision_score,recall_score,class_wise_accuracy]\n",
    "predictions_all = [predictions_logreg, predictions_dt, predictions_rf, predictions_mlp]\n",
    "# [print(each.shape) for each in predictions_all]\n",
    "\n",
    "all_metrics = [each_metric_method(y_test, each_model_prediction,average=None, labels=label_order) for each_metric_method in metric_methods for each_model_prediction in predictions_all]\n",
    "\n",
    "metrics_df = pd.DataFrame(all_metrics).T\n",
    "metrics_df.index = label_order\n",
    "metrics_df.columns = [each_model+\"_\"+each_metric for each_metric in metrics for each_model in models ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below table compares the classification metrics for each level and model. We have calculated three metrics for each model and level(levels here refers to each of the unique levels of the variable we are predicting: \"unacc\", \"acc\", \"good\", \"vgood\"). The metrics that we are calculating are: \n",
    "<ul>\n",
    "<li><i><b>Accuracy: </b></i>measures the fraction of all instances that are correctly categorized</li>\n",
    "<li><i><b>Recall: </b></i>is the proportion of people that tested positive and are positive (True Positive, TP) of all the people that actually are positive </li>\n",
    "<li><i><b>Precision: </b></i>it is the proportion of true positives out of all positive results</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Precisionrecall.png\" width = 300px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg_precision</th>\n",
       "      <th>dt_precision</th>\n",
       "      <th>rf_precision</th>\n",
       "      <th>mlp_precision</th>\n",
       "      <th>logreg_recall</th>\n",
       "      <th>dt_recall</th>\n",
       "      <th>rf_recall</th>\n",
       "      <th>mlp_recall</th>\n",
       "      <th>logreg_accuracy</th>\n",
       "      <th>dt_accuracy</th>\n",
       "      <th>rf_accuracy</th>\n",
       "      <th>mlp_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.756494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacc</th>\n",
       "      <td>0.973203</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vgood</th>\n",
       "      <td>0.910714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       logreg_precision  dt_precision  rf_precision  mlp_precision  \\\n",
       "acc            0.756494           1.0           1.0            1.0   \n",
       "good           0.640000           1.0           1.0            1.0   \n",
       "unacc          0.973203           1.0           1.0            1.0   \n",
       "vgood          0.910714           1.0           1.0            1.0   \n",
       "\n",
       "       logreg_recall  dt_recall  rf_recall  mlp_recall  logreg_accuracy  \\\n",
       "acc         0.882576        1.0        1.0         1.0         0.882576   \n",
       "good        0.307692        1.0        1.0         1.0         0.307692   \n",
       "unacc       0.947805        1.0        1.0         1.0         0.947805   \n",
       "vgood       1.000000        1.0        1.0         1.0         1.000000   \n",
       "\n",
       "       dt_accuracy  rf_accuracy  mlp_accuracy  \n",
       "acc            1.0          1.0           1.0  \n",
       "good           1.0          1.0           1.0  \n",
       "unacc          1.0          1.0           1.0  \n",
       "vgood          1.0          1.0           1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "456px",
    "left": "477px",
    "right": "20px",
    "top": "177px",
    "width": "709px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
